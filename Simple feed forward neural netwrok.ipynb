{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57130278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef, f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a600bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = 'Hall_2012_cleaned.csv'\n",
    "# file_path = 'Jeyaraman_2020_cleaned.csv'\n",
    "# file_path = 'Radjenovic_2013_cleaned.csv'\n",
    "file_path = 'Smid_2020_cleaned.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, delimiter=',')\n",
    "df = df.dropna(axis=0)\n",
    "df_sample = df.copy()\n",
    "df_sample = df.reset_index(drop=True)\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonym = lemma.name().replace('_', ' ')\n",
    "            synonyms.add(synonym)\n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)\n",
    "    return list(synonyms)\n",
    "\n",
    "def synonym_replacement(sentence, n):\n",
    "    words = sentence.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if word.isalpha()]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(list(synonyms))\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n: # only replace up to n words\n",
    "            break\n",
    "\n",
    "    sentence = ' '.join(new_words)\n",
    "    return sentence\n",
    "\n",
    "def augment_text(df, minority_class, augment_by=0.9):\n",
    "    minority_df = df[df['label_included'] == minority_class]\n",
    "    n_augmentations = int(len(minority_df) * augment_by)\n",
    "    \n",
    "    augmented_texts = []\n",
    "    for _ in range(n_augmentations):\n",
    "        original_text = random.choice(minority_df['Corpus'].tolist())\n",
    "        augmented_text = synonym_replacement(original_text, n=1) # You can adjust n for more replacements\n",
    "        augmented_texts.append(augmented_text)\n",
    "    \n",
    "    # Add augmented texts to the dataframe\n",
    "    augmented_df = pd.DataFrame(augmented_texts, columns=['Corpus'])\n",
    "    augmented_df['label_included'] = minority_class\n",
    "    return pd.concat([df, augmented_df], ignore_index=True)\n",
    "\n",
    "# Assuming your minority class is identified, for example, as 1\n",
    "df_augmented = augment_text(df, minority_class=1, augment_by=0.5)\n",
    "\n",
    "\n",
    "df_sample = pd.concat([df, df_augmented], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataframe to mix original and augmented examples (optional)\n",
    "df_sample = df_sample.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X = df_sample['Corpus']\n",
    "y = df_sample['label_included']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "NUM_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "\n",
    "# Lists to store evaluation metrics\n",
    "balanced_acc_scores = []\n",
    "mcc_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "stratified_kfold = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dabeb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=200\n",
    "learning_rate = 0.001\n",
    "batch_size = 2\n",
    "hidden_units = 128\n",
    "projection_units = 128\n",
    "epochs = 10\n",
    "dropout_rate = 0.3\n",
    "temperature = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edec0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(encoder, trainable=True):\n",
    "    input_shape = (encoder.get_feature_names_out().shape[0],)\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape, sparse=True, dtype=tf.float32)\n",
    "    \n",
    "    # Add a single dense layer for classification\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"simple-text-classifier\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.001,),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            keras.metrics.BinaryAccuracy(),\n",
    "            balanced_accuracy_metric,\n",
    "            f1_score_metric,\n",
    "            mcc_metric,\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53562e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63db3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_classifier_2(input_shape, trainable=True):\n",
    "    inputs = keras.Input(shape=input_shape, dtype=tf.float32)\n",
    "\n",
    "    # Add a single dense layer for classification\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"simple-text-classifier\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.001,),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            keras.metrics.BinaryAccuracy(),\n",
    "            balanced_accuracy_metric,\n",
    "            f1_score_metric,\n",
    "            mcc_metric,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f10670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc_metric(y_true, y_pred):\n",
    "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    true_negatives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    false_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    false_negatives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "    \n",
    "    denominator = tf.keras.backend.sqrt((true_positives + false_positives) * (true_positives + false_negatives) * (true_negatives + false_positives) * (true_negatives + false_negatives))\n",
    "    mcc = (true_positives * true_negatives - false_positives * false_negatives) / (denominator + tf.keras.backend.epsilon())\n",
    "    \n",
    "    return mcc\n",
    "\n",
    "\n",
    "def balanced_accuracy_metric(y_true, y_pred):\n",
    "    actual_positives = tf.math.reduce_sum(y_true)\n",
    "    actual_negatives = tf.math.reduce_sum(1 - y_true)\n",
    "    \n",
    "    epsilon = 1e-7  # Small constant to avoid division by zero\n",
    "\n",
    "    true_positives = tf.math.reduce_sum(y_true * tf.round(y_pred))\n",
    "    true_negatives = tf.math.reduce_sum((1 - y_true) * tf.round(1 - y_pred))\n",
    "    \n",
    "    balanced_accuracy = 0.5 * (true_positives / (actual_positives + epsilon) + true_negatives / (actual_negatives + epsilon))\n",
    "    \n",
    "    return balanced_accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def f1_score_metric(y_true, y_pred):\n",
    "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
    "    actual_positives = tf.keras.backend.sum(y_true)\n",
    "    \n",
    "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "    recall = true_positives / (actual_positives + tf.keras.backend.epsilon())\n",
    "    \n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "    \n",
    "    return f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e617e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_tf_idf_classifier(X_train, y_train, X_test, y_test, kfold):\n",
    "    # Data preprocessing\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(2, 3), max_df=0.7)\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    X_train_tfidf_standardized = scaler.fit_transform(X_train_tfidf)\n",
    "    X_test_tfidf_standardized = scaler.transform(X_test_tfidf)\n",
    "\n",
    "    # Convert the standardized sparse matrix to a dense tensor\n",
    "    X_train_tfidf_tensor = tf.convert_to_tensor(X_train_tfidf_standardized.toarray(), dtype=tf.float32)\n",
    "    X_test_tfidf_tensor = tf.convert_to_tensor(X_test_tfidf_standardized.toarray(), dtype=tf.float32)\n",
    "\n",
    "#     # Resample using SMOTEENN\n",
    "#     X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train_tfidf_tensor, y_train)\n",
    "\n",
    "    # Build and compile the TF-IDF classifier model\n",
    "    classifier_model = create_classifier(tfidf_vectorizer, trainable=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = classifier_model.fit(\n",
    "        X_train_tfidf_tensor, y_train,\n",
    "        validation_data=(X_test_tfidf_tensor, y_test),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred_proba = classifier_model.predict(X_test_tfidf_tensor)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    return balanced_acc, mcc, f1, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_idx, (train_index, test_index) in enumerate(stratified_kfold.split(X, y_encoded), 1):\n",
    "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_encoded[train_index], y_encoded[test_index]\n",
    "\n",
    "    # Train and evaluate TF-IDF classifier model\n",
    "    balanced_acc_fold, mcc_fold, f1_fold, recall_fold = train_evaluate_tf_idf_classifier(\n",
    "        X_train_fold, y_train_fold, X_test_fold, y_test_fold, stratified_kfold\n",
    "    )\n",
    "\n",
    "    # Append scores to lists\n",
    "    balanced_acc_scores.append(balanced_acc_fold)\n",
    "    mcc_scores.append(mcc_fold)\n",
    "    f1_scores.append(f1_fold)\n",
    "    recall_scores.append(recall_fold)\n",
    "\n",
    "    # Print results for the fold\n",
    "    print(f\"Fold {fold_idx}:\")\n",
    "    print(f\"  Balanced Accuracy: {balanced_acc_fold:.2f}\")\n",
    "    print(f\"  F1-Score: {f1_fold:.2f}\")\n",
    "    print(f\"  Matthew's Correlation Coefficient: {mcc_fold:.2f}\")\n",
    "    print(f\"  Recall: {recall_fold:.2f}\")\n",
    "\n",
    "# Print average scores\n",
    "print(\"Average Scores sentences:\")\n",
    "print(f\"{np.mean(balanced_acc_scores):.2f}\")\n",
    "print(f\"{np.mean(f1_scores):.2f}\")\n",
    "print(f\"{np.mean(mcc_scores):.2f}\")\n",
    "print(f\"{np.mean(recall_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "balanced_acc_scores = []\n",
    "mcc_scores = []\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b820372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_encoder():\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length),\n",
    "        GlobalAveragePooling1D()\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2617f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_sequences = tokenizer.texts_to_sequences(X)\n",
    "max_sequence_length = max(len(seq) for seq in X_sequences)\n",
    "X_padded = pad_sequences(X_sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Define vocabulary size and embedding dimension\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8781838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_idx, (train_index, test_index) in enumerate(stratified_kfold.split(X_padded, y_encoded), 1):\n",
    "    X_train_fold, X_test_fold = X_padded[train_index], X_padded[test_index]\n",
    "    y_train_fold, y_test_fold = y_encoded[train_index], y_encoded[test_index]\n",
    "\n",
    "    # Create and compile the simple encoder model\n",
    "    simple_encoder = create_simple_encoder()\n",
    "    simple_encoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the simple encoder on the training data\n",
    "    simple_encoder.fit(X_train_fold, y_train_fold, epochs=5, batch_size=32, verbose=0)\n",
    "\n",
    "    # Get embeddings for the training and test data\n",
    "    X_train_embeddings_fold = simple_encoder.predict(X_train_fold)\n",
    "    X_test_embeddings_fold = simple_encoder.predict(X_test_fold)\n",
    "\n",
    "    # Standardize the features if they haven't been standardized\n",
    "    if not np.all(np.isclose(np.mean(X_train_embeddings_fold), 0.0, atol=1e-4)) or not np.all(np.isclose(np.std(X_train_embeddings_fold), 1.0, atol=1e-4)):\n",
    "        X_train_embeddings_fold = scaler.fit_transform(X_train_embeddings_fold)\n",
    "        X_test_embeddings_fold = scaler.transform(X_test_embeddings_fold)\n",
    "\n",
    "\n",
    "\n",
    "    # Create and compile the classifier model\n",
    "    classifier_model = create_classifier_2((X_test_embeddings_fold.shape[1],))\n",
    "\n",
    "    # Train the classifier model on the entire resampled training data\n",
    "    classifier_model.fit(\n",
    "        X_train_embeddings_fold,  \n",
    "        y_train_fold,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0 \n",
    "    )\n",
    "\n",
    "    y_pred_fold = (classifier_model.predict(X_test_embeddings_fold) > 0.5).astype(int)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    balanced_acc_fold = balanced_accuracy_score(y_test_fold, y_pred_fold)\n",
    "    mcc_fold = matthews_corrcoef(y_test_fold, y_pred_fold)\n",
    "    f1_fold = f1_score(y_test_fold, y_pred_fold)\n",
    "    precision_fold = precision_score(y_test_fold, y_pred_fold)\n",
    "    recall_fold = recall_score(y_test_fold, y_pred_fold)\n",
    "\n",
    "    # Append the scores to the lists\n",
    "    balanced_acc_scores.append(balanced_acc_fold)\n",
    "    mcc_scores.append(mcc_fold)\n",
    "    f1_scores.append(f1_fold)\n",
    "    precision_scores.append(precision_fold)\n",
    "    recall_scores.append(recall_fold)\n",
    "\n",
    "    # Print the evaluation metrics for this fold\n",
    "    print(f\"Fold {fold_idx}:\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc_fold:.2f}\")\n",
    "    print(f\"F1-Score: {f1_fold:.2f}\")\n",
    "    print(f\"Matthew's Correlation Coefficient: {mcc_fold:.2f}\")\n",
    "    print(f\"precision: {precision_fold:.2f}\")\n",
    "    print(f\"Recall: {recall_fold:.2f}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf088f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Scores sentences:\")\n",
    "print(f\"{np.mean(mcc_scores):.2f}\")\n",
    "print(f\"{np.mean(balanced_acc_scores):.2f}\")\n",
    "print(f\"{np.mean(f1_scores):.2f}\")\n",
    "print(f\"{np.mean(precision_scores):.2f}\")\n",
    "print(f\"{np.mean(recall_scores):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
