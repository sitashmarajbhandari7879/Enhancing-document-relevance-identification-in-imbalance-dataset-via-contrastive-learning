{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1976d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaModel\n",
    "from transformers import  BertModel, BertForSequenceClassification, DistilBertModel, GPT2Model, GPT2Tokenizer, GPT2Config, GPT2ForSequenceClassification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import precision_recall_fscore_support, matthews_corrcoef, balanced_accuracy_score\n",
    "\n",
    "\n",
    "from SupCL_Seq import SupCsTrainer\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# file_path = 'Hall_2012_cleaned.csv'\n",
    "file_path = 'Jeyaraman_2020_cleaned.csv'\n",
    "# file_path = 'Radjenovic_2013_cleaned.csv'\n",
    "# file_path = 'Smid_2020_cleaned.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, delimiter=',')\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "df_sample = df.copy()\n",
    "df_sample = df_sample.sample(frac=1).reset_index(drop=True)\n",
    "class_counts = df_sample['label_included'].value_counts()\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary') # or 'micro', 'macro', 'weighted' based on your needs\n",
    "    mcc = matthews_corrcoef(labels, predictions)\n",
    "    balanced_acc = balanced_accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'mcc': mcc,\n",
    "        'balanced_accuracy': balanced_acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11213647",
   "metadata": {},
   "source": [
    "# Data augmentation methodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008bfe8d",
   "metadata": {},
   "source": [
    "# Synonmsy replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ef160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet, words\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonym = lemma.name().replace('_', ' ')\n",
    "            synonyms.add(synonym)\n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)\n",
    "    return list(synonyms)\n",
    "\n",
    "def synonym_replacement(sentence, n):\n",
    "    words = sentence.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if word.isalpha()]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(synonyms)\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def random_insertion(sentence, n):\n",
    "    words = sentence.split()\n",
    "    for _ in range(n):\n",
    "        new_synonyms = []\n",
    "        random_word = random.choice(words)\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if synonyms:\n",
    "            new_synonym = random.choice(synonyms)\n",
    "            insert_position = random.randint(0, len(words))\n",
    "            words.insert(insert_position, new_synonym)\n",
    "    return ' '.join(words)\n",
    "\n",
    "def random_deletion(sentence, p):\n",
    "    words = sentence.split()\n",
    "    if len(words) == 1:\n",
    "        return sentence\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        r = random.uniform(0, 1)\n",
    "        if r > p:\n",
    "            new_words.append(word)\n",
    "    if len(new_words) == 0:\n",
    "        return random.choice(words)\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def augment_text(df, minority_class, augment_by):\n",
    "    minority_df = df[df['label_included'] == minority_class]\n",
    "    n_minority = len(minority_df)\n",
    "    n_augmentations = int(n_minority * augment_by)\n",
    "    augmented_texts = []\n",
    "    for _ in range(n_augmentations):\n",
    "        original_text = random.choice(minority_df['Corpus'].tolist())\n",
    "        augmented_text = original_text\n",
    "        # Choose a random augmentation technique\n",
    "        augmentation_type = random.choice(['synonym_replacement', 'random_insertion', 'random_deletion'])\n",
    "        if augmentation_type == 'synonym_replacement':\n",
    "            augmented_text = synonym_replacement(augmented_text, n=1)\n",
    "        elif augmentation_type == 'random_insertion':\n",
    "            augmented_text = random_insertion(augmented_text, n=1)\n",
    "        elif augmentation_type == 'random_deletion':\n",
    "            augmented_text = random_deletion(augmented_text, p=0.25)\n",
    "        augmented_texts.append(augmented_text)\n",
    "    augmented_df = pd.DataFrame(augmented_texts, columns=['Corpus'])\n",
    "    augmented_df['label_included'] = minority_class\n",
    "    return augmented_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a83d6be",
   "metadata": {},
   "source": [
    "# Sentences Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6399266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# def shuffle_sentence(sentence):\n",
    "\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Shuffles the words in a sentence, preserving the meaning but altering the structure.\n",
    "#     \"\"\"\n",
    "#     words = sentence.split()\n",
    "#     random.shuffle(words)\n",
    "#     return ' '.join(words)\n",
    "\n",
    "# def augment_text_with_shuffling(df, minority_class, augment_by=0.5):\n",
    "#     \"\"\"\n",
    "#     Augments the given dataframe by shuffling sentences of the minority class.\n",
    "#     \"\"\"\n",
    "#     minority_df = df[df['label_included'] == minority_class]\n",
    "#     n_augmentations = int(len(minority_df) * augment_by)\n",
    "    \n",
    "#     augmented_texts = []\n",
    "#     for _, row in minority_df.sample(n_augmentations, replace=True).iterrows():\n",
    "#         original_text = row['Corpus']\n",
    "#         augmented_text = shuffle_sentence(original_text)\n",
    "#         augmented_texts.append(augmented_text)\n",
    "    \n",
    "#     augmented_df = pd.DataFrame(augmented_texts, columns=['Corpus'])\n",
    "#     augmented_df['label_included'] = minority_class\n",
    "#     return augmented_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7959a9b",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import wordnet\n",
    "# import random\n",
    "\n",
    "# def get_synonyms(word):\n",
    "#     synonyms = set()\n",
    "#     for syn in wordnet.synsets(word):\n",
    "#         for lemma in syn.lemmas():\n",
    "#             synonym = lemma.name().replace('_', ' ')\n",
    "#             synonyms.add(synonym)\n",
    "#     if word in synonyms:\n",
    "#         synonyms.remove(word)\n",
    "#     return list(synonyms)\n",
    "\n",
    "# def synonym_replacement(sentence, n):\n",
    "#     words = sentence.split()\n",
    "#     new_words = words.copy()\n",
    "#     random_word_list = list(set([word for word in words if word.isalpha()]))\n",
    "#     random.shuffle(random_word_list)\n",
    "#     num_replaced = 0\n",
    "#     for random_word in random_word_list:\n",
    "#         synonyms = get_synonyms(random_word)\n",
    "#         if len(synonyms) >= 1:\n",
    "#             synonym = random.choice(list(synonyms))\n",
    "#             new_words = [synonym if word == random_word else word for word in new_words]\n",
    "#             num_replaced += 1\n",
    "#         if num_replaced >= n: # only replace up to n words\n",
    "#             break\n",
    "\n",
    "#     sentence = ' '.join(new_words)\n",
    "#     return sentence\n",
    "\n",
    "# def augment_text(df, minority_class, augment_by):\n",
    "#     minority_df = df[df['label_included'] == minority_class]\n",
    "    \n",
    "#     n_minority = len(minority_df)\n",
    "#     n_augmentations = int(n_minority * augment_by)\n",
    "    \n",
    "#     augmented_texts = []\n",
    "#     for _ in range(n_augmentations):\n",
    "#         original_text = random.choice(minority_df['Corpus'].tolist())\n",
    "#         augmented_text = synonym_replacement(original_text, n=1) # You can adjust n for more replacements\n",
    "#         augmented_texts.append(augmented_text)\n",
    "    \n",
    "#     # Create a DataFrame for augmented minority samples\n",
    "#     augmented_df = pd.DataFrame(augmented_texts, columns=['Corpus'])\n",
    "#     augmented_df['label_included'] = minority_class\n",
    "    \n",
    "#     return augmented_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0d5897",
   "metadata": {},
   "source": [
    "# Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Initialize the summarization pipeline with a pre-trained model\n",
    "# summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# def summarize_text(text):\n",
    "#     \"\"\"\n",
    "#     Summarizes the given text using a pre-trained summarization model.\n",
    "#     \"\"\"\n",
    "#     summary_list = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "#     summary_text = summary_list[0]['summary_text']\n",
    "#     return summary_text\n",
    "\n",
    "# def augment_text_with_summarization(df, minority_class, augment_by=0.5):\n",
    "#     \"\"\"\n",
    "#     Augments the given dataframe by summarizing texts of the minority class.\n",
    "#     \"\"\"\n",
    "#     minority_df = df[df['label_included'] == minority_class]\n",
    "#     n_augmentations = int(len(minority_df) * augment_by)\n",
    "    \n",
    "#     augmented_texts = []\n",
    "#     for _, row in minority_df.sample(n_augmentations, replace=True).iterrows():\n",
    "#         original_text = row['Corpus']\n",
    "#         try:\n",
    "#             augmented_text = summarize_text(original_text)\n",
    "#             augmented_texts.append(augmented_text)\n",
    "#         except Exception as e:\n",
    "#             print(f\"An error occurred during summarization: {e}\")\n",
    "    \n",
    "#     augmented_df = pd.DataFrame(augmented_texts, columns=['Corpus'])\n",
    "#     augmented_df['label_included'] = minority_class\n",
    "#     return augmented_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f4be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented = augment_text(df, minority_class=1, augment_by=0.5)\n",
    "df_sample = pd.concat([df, df_augmented], ignore_index=True)\n",
    "\n",
    "df_sample = df_sample.sample(frac=1).reset_index(drop=True)\n",
    "class_counts = df_sample['label_included'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7464abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts = df_sample['Corpus'].tolist()\n",
    "labels = df_sample['label_included'].tolist()\n",
    "max_sequence_length = max(len(text.split()) for text in df_sample['Corpus'])  \n",
    "num_classes = 1\n",
    "input_shape = (max_sequence_length,)\n",
    "from collections import Counter\n",
    "token_counts = Counter(word for sentence in  df_sample['Corpus'] for word in sentence.split())\n",
    "vocab_size = len(token_counts)\n",
    "input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea69936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"bert-base-uncased\"  # Changed to use BERT base model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf8105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels)  # Convert labels to a tensor for consistent indexing\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]  # Direct tensor indexing\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d48f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "\n",
    "\n",
    "class MetricsLogger(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.training_loss = []\n",
    "        self.validation_loss = []\n",
    "        self.accuracy = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        # Logs might contain training loss, validation loss, and validation metrics\n",
    "        if 'loss' in logs:  # Training loss\n",
    "            self.training_loss.append(logs['loss'])\n",
    "        if 'eval_loss' in logs:  # Validation loss\n",
    "            self.validation_loss.append(logs['eval_loss'])\n",
    "        if 'eval_accuracy' in logs:  # Accuracy\n",
    "            self.accuracy.append(logs['eval_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaff770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, dataloader):\n",
    "    model.eval()\n",
    "    model.to('cuda')\n",
    "\n",
    "    embeddings = []\n",
    "    for batch in dataloader:\n",
    "        inputs = {key: val.to('cuda') for key, val in batch.items() if key != 'labels'}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # Take the embeddings from the last hidden state for the [CLS] token\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            embeddings.append(cls_embeddings)\n",
    "\n",
    "    # Convert list of embeddings into a single numpy array\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "fold_metrics = {\n",
    "    'mcc': [],\n",
    "     'balanced_accuracy': [],\n",
    "    'f1': [],\n",
    "    'precision': [],\n",
    "    'recall': []\n",
    " }\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(texts, labels), 1):\n",
    "    print(f\"Fold {fold}/{n_splits}\")\n",
    "\n",
    "    # Splitting the data\n",
    "    train_texts, val_texts = np.array(texts)[train_idx], np.array(texts)[val_idx]\n",
    "    train_labels, val_labels = np.array(labels)[train_idx], np.array(labels)[val_idx]\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # Tokenization\n",
    "    train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, return_tensors='pt')\n",
    "    val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "    # Dataset preparation\n",
    "    train_dataset = CustomDataset(train_encodings, train_labels.tolist())\n",
    "    val_dataset = CustomDataset(val_encodings, val_labels.tolist())\n",
    "\n",
    "    # Initialize the model for contrastive learning\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "#     model = BertModel.from_pretrained(model_name)  # Changed to BERT model\n",
    "    model = RobertaModel.from_pretrained(model_name)\n",
    "   \n",
    "\n",
    "\n",
    "    pre_train_embeddings = extract_embeddings(model, train_dataloader)\n",
    "#\n",
    "\n",
    "    # TrainingArguments for SupCsTrainer\n",
    "    CL_args = TrainingArguments(\n",
    "        output_dir=f'./results/fold_{fold}',\n",
    "        save_total_limit = 1,\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=8,  \n",
    "        evaluation_strategy = 'no',\n",
    "        logging_strategy='epoch',\n",
    "        \n",
    "        learning_rate = 5e-05,\n",
    "        eval_steps = 500,\n",
    "        warmup_steps=50, \n",
    "        report_to ='tensorboard',\n",
    "        weight_decay=0.01,                  \n",
    "        logging_dir=f'./logs/fold_{fold}',\n",
    "      \n",
    "    )\n",
    "\n",
    "    # Initialize and train SupCsTrainer\n",
    "    SupCL_trainer = SupCsTrainer.SupCsTrainer(\n",
    "        w_drop_out=[0.0,0.05],\n",
    "        temperature= 0.05,\n",
    "        def_drop_out=0.1,\n",
    "        pooling_strategy='mean',\n",
    "        model = model,\n",
    "        args = CL_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    SupCL_trainer.train()\n",
    "    SupCL_trainer.save_model(f'./cs_baseline/fold_{fold}')\n",
    "\n",
    "#     Load the trained model for fine-tuning\n",
    "    fine_tune_model = RobertaForSequenceClassification.from_pretrained(f'./cs_baseline/fold_{fold}', num_labels=2)\n",
    "    fine_tuned_base_model = fine_tune_model.roberta\n",
    "\n",
    "#     fine_tune_model = BertForSequenceClassification.from_pretrained(f'./cs_baseline/fold_{fold}', num_labels=2)\n",
    "#     fine_tuned_base_model = fine_tune_model.bert  # Adjusted to use BERT\n",
    "\n",
    "    \n",
    "\n",
    "    # Freeze the base model's parameters\n",
    "    for param in fine_tune_model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    post_train_embeddings = extract_embeddings(fine_tuned_base_model, train_dataloader)\n",
    "\n",
    "    # TrainingArguments for fine-tuning\n",
    "    fine_tune_args = TrainingArguments(\n",
    "        output_dir = f'./fine_tuned/fold_{fold}',\n",
    "        save_total_limit = 1,\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=30,  \n",
    "        per_device_eval_batch_size=10,\n",
    "        evaluation_strategy = 'epoch',\n",
    "        eval_steps = 500,\n",
    " \n",
    "        learning_rate = 1e-03,\n",
    "        logging_strategy='epoch',\n",
    "     \n",
    "        report_to ='tensorboard',\n",
    "        weight_decay=0.01, \n",
    "    \n",
    "        logging_dir=f'./logs/fine_tuned/fold_{fold}',\n",
    "    )\n",
    "    metrics_logger = MetricsLogger()\n",
    "\n",
    "    # Initialize Trainer for fine-tuning\n",
    "    fine_tune_trainer = Trainer(\n",
    "        model=fine_tune_model,\n",
    "        args=fine_tune_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        callbacks=[metrics_logger],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    fine_tune_trainer.train()\n",
    "    # Assuming fine_tune_trainer.evaluate() returns a dictionary with your metrics\n",
    "    eval_metrics = fine_tune_trainer.evaluate()\n",
    "\n",
    "    # Store the metrics\n",
    "    fold_metrics['precision'].append(eval_metrics['eval_precision'])\n",
    "    fold_metrics['recall'].append(eval_metrics['eval_recall'])\n",
    "    fold_metrics['f1'].append(eval_metrics['eval_f1'])\n",
    "    fold_metrics['mcc'].append(eval_metrics['eval_mcc'])\n",
    "    fold_metrics['balanced_accuracy'].append(eval_metrics['eval_balanced_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate aggregate metrics across all folds\n",
    "aggregate_metrics = {metric: np.mean(values) for metric, values in fold_metrics.items()}\n",
    "\n",
    "print(\"Aggregate Metrics Across All Folds:\")\n",
    "for metric, value in aggregate_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb52aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev_metrics = {\n",
    "    'precision': np.std(fold_metrics['precision']),\n",
    "    'recall': np.std(fold_metrics['recall']),\n",
    "    'f1': np.std(fold_metrics['f1']),\n",
    "    'mcc': np.std(fold_metrics['mcc']),\n",
    "    'balanced_accuracy': np.std(fold_metrics['balanced_accuracy'])\n",
    "}\n",
    "\n",
    "# Optionally, you can print these values to see them\n",
    "for metric, std_dev in std_dev_metrics.items():\n",
    "    print(f\"The standard deviation for {metric} is {std_dev:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use t-SNE to reduce dimensionality for visualization\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_initial_embeddings = tsne.fit_transform(pre_train_embeddings)\n",
    "tsne_final_embeddings = tsne.fit_transform(post_train_embeddings)\n",
    "\n",
    "# Visualize the embeddings\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(tsne_initial_embeddings[:, 0], tsne_initial_embeddings[:, 1], c=train_labels, cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "plt.title('Initial Embeddings')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(tsne_final_embeddings[:, 0], tsne_final_embeddings[:, 1], c=train_labels, cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "plt.title('Final Embeddings After Training')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "pre_silhouette = silhouette_score(pre_train_embeddings, train_labels)\n",
    "post_silhouette = silhouette_score(post_train_embeddings, train_labels)\n",
    "\n",
    "print(f\"Silhouette score before training: {pre_silhouette}\")\n",
    "print(f\"Silhouette score after training: {post_silhouette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(metrics_logger.training_loss, label='Training Loss')\n",
    "plt.plot(metrics_logger.validation_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
